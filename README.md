# Cyberbullying-Using-BERT 

**INTRODUCTION**

Every day, thousands of people face verbal abuse online. The scars are digital but the pain is real. Behind every tweet or comment lies a personâ€”and sometimes, a victim.

This project isn't just about building a classifier. Itâ€™s about creating a digital shieldâ€”using the power of NLP and deep learning to fight cyberbullying.

![image](https://github.com/user-attachments/assets/b976f87e-f417-4d05-b61e-6220204db434)

ğŸ” **PROBLEM STATEMENT** â€“ The Battle Against Toxicity
With the rise of social media, cyberbullying has grown rampant. Manual moderation is impossible at scale. What we need is:

A model that understands language contextually.

One that can detect subtle aggression, veiled hate, or sarcasm.

A system that can evolve with the ever-changing vocabulary of the internet.


ğŸ¯ **OBJECTIVE** â€“ What Weâ€™re Trying to Solve
The goal of this project is to:

Automatically detect cyberbullying across different text categories.

Categorize bullying types like age-based, gender-based, religion-based, etc.

Build an interpretable and scalable model for real-world deployment.


ğŸ—ï¸ **The ARCHITECTURE** â€“ How the Model Thinks
We use BERT (Bidirectional Encoder Representations from Transformers), one of the most advanced models for understanding language. Here's how we applied it:

ğŸ”¡ Tokenized and cleaned real-world tweets/comments.

âš™ï¸ Fine-tuned a pre-trained BERT model for text classification.

ğŸ§ª Evaluated performance using precision, recall, F1-score.

![image](https://github.com/user-attachments/assets/239eb104-9812-4e34-8d2d-b2337c8306e3)


