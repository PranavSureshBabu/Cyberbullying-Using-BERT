# Cyberbullying-Using-BERT 

**INTRODUCTION**

Every day, thousands of people face verbal abuse online. The scars are digital but the pain is real. Behind every tweet or comment lies a person—and sometimes, a victim.

This project isn't just about building a classifier. It’s about creating a digital shield—using the power of NLP and deep learning to fight cyberbullying.

![image](https://github.com/user-attachments/assets/b976f87e-f417-4d05-b61e-6220204db434)

🔍 **PROBLEM STATEMENT** – The Battle Against Toxicity
With the rise of social media, cyberbullying has grown rampant. Manual moderation is impossible at scale. What we need is:

A model that understands language contextually.

One that can detect subtle aggression, veiled hate, or sarcasm.

A system that can evolve with the ever-changing vocabulary of the internet.


🎯 **OBJECTIVE** – What We’re Trying to Solve
The goal of this project is to:

Automatically detect cyberbullying across different text categories.

Categorize bullying types like age-based, gender-based, religion-based, etc.

Build an interpretable and scalable model for real-world deployment.


🏗️ **The ARCHITECTURE** – How the Model Thinks
We use BERT (Bidirectional Encoder Representations from Transformers), one of the most advanced models for understanding language. Here's how we applied it:

🔡 Tokenized and cleaned real-world tweets/comments.

⚙️ Fine-tuned a pre-trained BERT model for text classification.

🧪 Evaluated performance using precision, recall, F1-score.

![image](https://github.com/user-attachments/assets/239eb104-9812-4e34-8d2d-b2337c8306e3)


